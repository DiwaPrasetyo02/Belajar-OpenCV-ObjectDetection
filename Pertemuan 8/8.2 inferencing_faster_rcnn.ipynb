{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Inferencing Faster R-CNN\n",
    "- Inferencing faster R-CNN OpenCV DNN\n",
    "- Inferencing faster R-CNN ONNX Runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Install necesarry package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx\n",
    "!pip install onnxruntime\n",
    "!pip install --force-reinstall opencv-python==4.7.0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 Inferencing faster R-CNN OpenCV DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_model(onnx_model_path):\n",
    "    # Load the ONNX model\n",
    "    net = cv2.dnn.readNetFromONNX(onnx_model_path)\n",
    "    return net\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load the image and resize to 224x224\n",
    "    image = cv2.imread(image_path)\n",
    "    image_resized = cv2.resize(image, (224, 224))\n",
    "    blob = cv2.dnn.blobFromImage(image_resized, 1/255.0, (224, 224), swapRB=True, crop=False)\n",
    "    return image, image_resized, blob\n",
    "\n",
    "def run_inference(net, blob):\n",
    "    # Set the input to the network\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    # Forward pass through the network\n",
    "    outputs = net.forward()  # Get all the output layers\n",
    "    return outputs\n",
    "\n",
    "def post_process(outputs, image_shape, threshold=0.5):\n",
    "    boxes, labels, scores = [], [], []\n",
    "    \n",
    "    # Assuming output format: boxes, labels, scores\n",
    "    for output in outputs:\n",
    "        # Iterate through each detected object\n",
    "        for detection in output:\n",
    "            confidence = detection[2]\n",
    "            if confidence > threshold:\n",
    "                # Extract box coordinates (x_min, y_min, x_max, y_max)\n",
    "                box = detection[3:7] * np.array([image_shape[1], image_shape[0], image_shape[1], image_shape[0]])\n",
    "                boxes.append(box.astype(\"int\"))\n",
    "                labels.append(int(detection[1]))\n",
    "                scores.append(float(confidence))\n",
    "    \n",
    "    return boxes, labels, scores\n",
    "\n",
    "def draw_detections(image, boxes, labels, scores, class_names=None):\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        # Draw the bounding box\n",
    "        cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "        label_text = f\"{class_names[label]}: {score:.2f}\" if class_names else f\"Label {label}: {score:.2f}\"\n",
    "        \n",
    "        # Put the label text\n",
    "        cv2.putText(image, label_text, (box[0], box[1] - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Main function to perform inference\n",
    "def main(image_path, onnx_model_path):\n",
    "    # Load the model\n",
    "    net = load_model(onnx_model_path)\n",
    "    \n",
    "    # Preprocess the image\n",
    "    original_image, resized_image, blob = preprocess_image(image_path)\n",
    "    \n",
    "    # Run inference\n",
    "    outputs = run_inference(net, blob)\n",
    "    \n",
    "    # Post-process the outputs\n",
    "    boxes, labels, scores = post_process(outputs, original_image.shape)\n",
    "    \n",
    "    # Define class names if available\n",
    "    class_names = [\"background\", \"scissors\"]  # Modify according to your dataset\n",
    "\n",
    "    # Draw the detections on the original image\n",
    "    result_image = draw_detections(original_image.copy(), boxes, labels, scores, class_names)\n",
    "    \n",
    "    # Display the result\n",
    "    cv2.imshow(\"Detections\", result_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "image_path = \"image2.jpg\"\n",
    "main(image_path, MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 Inferencing Faster R-CNN ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Load the ONNX model\n",
    "MODEL_NAME = \"fasterrcnn_resnet50_fpn_v2_scissors.onnx\"\n",
    "onnx_model = onnx.load(MODEL_NAME)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Run inference with ONNX Runtime\n",
    "ort_session = ort.InferenceSession(MODEL_NAME)\n",
    "\n",
    "# Load your image\n",
    "image_path = \"image2.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# Define the same transformations used during training\n",
    "transform = T.Compose([\n",
    "    T.Resize((224, 224)),  # Resize to match the model's input size, if needed\n",
    "    T.ToTensor(),          # Convert the image to a tensor\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "])\n",
    "\n",
    "# Apply transformations and add batch dimension\n",
    "input_tensor = transform(image).unsqueeze(0)  # Shape: [1, 3, 224, 224]\n",
    "\n",
    "# Convert tensor to numpy format\n",
    "input_image = input_tensor.numpy()\n",
    "\n",
    "# Example inference\n",
    "outputs = ort_session.run(None, {\"input\": input_image})\n",
    "print(\"ONNX model outputs:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to display the image with detected boxes and labels\n",
    "def display_detections(image_path, boxes, labels, scores, threshold=0.5, class_names=None):\n",
    "    \"\"\"\n",
    "    Displays the image with bounding boxes, labels, and confidence scores.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path: Path to the input image.\n",
    "    - boxes: Bounding boxes from the model output.\n",
    "    - labels: Class labels from the model output.\n",
    "    - scores: Confidence scores from the model output.\n",
    "    - threshold: Minimum confidence score to display a detection.\n",
    "    - class_names: List of class names corresponding to label indices.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = image.resize((224, 224))\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # Create a plot overlay for bounding boxes\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for box, label, score in zip(boxes, labels, scores):\n",
    "        if score >= threshold:  # Only display boxes above the confidence threshold\n",
    "            # Extract box coordinates\n",
    "            x_min, y_min, x_max, y_max = box\n",
    "\n",
    "            # Draw the bounding box\n",
    "            rect = patches.Rectangle(\n",
    "                (x_min, y_min), x_max - x_min, y_max - y_min,\n",
    "                linewidth=2, edgecolor=\"red\", facecolor=\"none\"\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "            # Add label and score\n",
    "            label_text = f\"{class_names[label]}: {score:.2f}\" if class_names else f\"Label {label}: {score:.2f}\"\n",
    "            plt.text(\n",
    "                x_min, y_min - 10, label_text,\n",
    "                color=\"red\", fontsize=12, backgroundcolor=\"white\"\n",
    "            )\n",
    "\n",
    "    # Show the plot\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage with outputs from the ONNX model\n",
    "image_path = \"image2.jpg\"\n",
    "boxes = outputs[0]  # Bounding boxes\n",
    "labels = outputs[1]  # Class labels\n",
    "scores = outputs[2]  # Confidence scores\n",
    "\n",
    "# Define class names if available, for example: class_names = [\"background\", \"scissors\", \"other\"]\n",
    "class_names = [\"background\", \"scissors\"]  # Modify based on your dataset\n",
    "\n",
    "# Display detections\n",
    "display_detections(image_path, boxes, labels, scores, threshold=0.5, class_names=class_names)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
