{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Intro to Two Stage Object Detection\n",
    "- Two-stage detectors typically consist of a <font color=\"orange\">region proposal</font> stage followed by a <font color=\"orange\">refinement stage</font>.\n",
    "- Historical timeline of prominent two-stage object detection models, <br><br>\n",
    "<img src=\"resource/two-stage-obj-det-timeline.png\" width=\"100%\"> <br><br>\n",
    "- Historical <font color=\"orange\">innovation</font> in two-stage object detection models, <br><br>\n",
    "<img src=\"resource/two-stage-obj-det-innovation.png\" width=\"100%\"> <br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=\"orange\">R-CNN (Regions with Convolutional Neural Networks)</font>\n",
    "    - Author : Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik\n",
    "    - Release Date : 2014\n",
    "    - Innovation : \n",
    "        - Introduced the use of <font color=\"orange\">region proposals</font> followed by CNN-based feature extraction for each region. \n",
    "        - R-CNN extracts around 2,000 region proposals using <font color=\"orange\">selective search</font> and classifies each region with a CNN.\n",
    "    - Architecture : \n",
    "        - Consists of three stages: \n",
    "            1. <font color=\"orange\">Region proposal</font> using <font color=\"orange\">selective search</font>, \n",
    "            2. <font color=\"orange\">Feature extraction</font> for each region using a <font color=\"orange\">pre-trained CNN</font> (AlexNet or similar), and \n",
    "            3. <font color=\"orange\">SVM classifier</font> to <font color=\"orange\">predict object labels</font> for each proposal.<br>\n",
    "            <img src=\"resource/r-cnn-arch.png\" width=\"900px\"><br>\n",
    "    - Benchmark : PASCAL VOC 2007 achieved 58.5% mAP.\n",
    "    - Paper : ['Rich feature hierarchies for accurate object detection and semantic segmentation' - arxiv.org](https://arxiv.org/pdf/1311.2524)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=\"orange\">Fast R-CNN</font>\n",
    "    - Author: Ross Girshick\n",
    "    - Release Date: 2015\n",
    "    - Innovation: \n",
    "        - Improved efficiency by <font color=\"orange\">sharing computation</font> over all region proposals. \n",
    "        - It introduces the <font color=\"orange\">ROI pooling</font> layer to crop features directly from a <font color=\"orange\">shared feature map</font> rather than processing each region independently.\n",
    "    - Architecture: \n",
    "        - Similar to R-CNN but uses a <font color=\"orange\">single forward pass</font> through the CNN to generate feature maps, then applies <font color=\"orange\">ROI pooling</font> to extract features for each region. \n",
    "        - Uses a <font color=\"orange\">softmax</font> classifier instead of SVM.<br>\n",
    "        <img src=\"resource/fast r-cnn-arch.png\" width=\"900px\"><br>\n",
    "    - Benchmark: PASCAL VOC 2012 achieved 70% mAP.\n",
    "    - Paper : ['Fast R-CNN' - arxiv.org](https://arxiv.org/pdf/1504.08083)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Faster R-CNN\n",
    "    - Author: Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun\n",
    "    - Release Date: 2016\n",
    "    - Innovation: \n",
    "        - Introduced a <font color=\"orange\">Region Proposal Network (RPN)</font> to replace selective search, making the model end-to-end trainable. \n",
    "        - The <font color=\"orange\">RPN</font> shares features with the detection network, improving speed and accuracy.\n",
    "    - Architecture: \n",
    "        - Combines <font color=\"orange\">RPN</font> and <font color=\"orange\">Fast R-CNN</font> into a unified network. \n",
    "        - The <font color=\"orange\">RPN</font> generates <font color=\"orange\">region proposals</font>, which are then refined by the <font color=\"orange\">Fast R-CNN</font> detection head using <font color=\"orange\">ROI pooling</font> and a <font color=\"orange\">fully connected layer</font>.<br>\n",
    "        <img src=\"resource/faster r-cnn-arch.png\" width=\"500px\"><br>\n",
    "    - Benchmark: COCO 2015, achieving around 34.9% mAP.\n",
    "    - Paper : ['Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks' - arxiv.org](https://arxiv.org/pdf/1506.01497)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
