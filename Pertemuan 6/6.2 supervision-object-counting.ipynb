{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Supervision Object Counting \n",
    "\n",
    "<img src=\"resource/rf-supervision-banner.png\" width=\"700px\"><br><br>\n",
    "- Computer Vision made easy and resusable.\n",
    "    - Whether you need to load your dataset from your hard drive, \n",
    "    - draw detections on an image or video, \n",
    "    - or count how many detections are in a zone. \n",
    "    - Supervision was designed to be model agnostic. \n",
    "    - Just plug in any classification, detection, or segmentation model. \n",
    "- Website : https://supervision.roboflow.com/latest/\n",
    "- Github : https://github.com/roboflow/supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Install Supervision\n",
    "\n",
    "- Since Supervision working in `python3.8`, we need to create new conda environment with name `BelajarSuperVision` using that python version\n",
    "- Open `Anaconda prompt`\n",
    "- create new environment `BelajarSuperVision`\n",
    "    ```\n",
    "    conda create --name BelajarSuperVision python=3.8\n",
    "    ```\n",
    "- activate environment\n",
    "    ```\n",
    "    conda activate BelajarSuperVision\n",
    "    ```\n",
    "- run to install supervision & ultralytics\n",
    "    ```\n",
    "    pip install ipykernel\n",
    "    pip install supervision\n",
    "    pip install ultralytics\n",
    "    pip install onnx --user\n",
    "    pip install onnxruntime\n",
    "    ```\n",
    "- Close VS Code, then reopen it\n",
    "- Open `6.2 supervision-object-counting.ipynb`\n",
    "- Choose `BelajarSuperVision` as python environment<br>\n",
    "<img src=\"resource/sv-image.png\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sv 0.23.0\n"
     ]
    }
   ],
   "source": [
    "# check if supervision was installed, required version >= 0.16.0\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "\n",
    "print(\"sv\", sv.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Object Counting Polygon Zone using Supervision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Singgle Polygon Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste the polygon point here!\n",
    "polygon = np.array([[421, 390], [524, 470], [190, 472], [241, 398]])# CHANGE TO YOUR OWN POLYGON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create supervision PolygonZone for the given polygon point\n",
    "zone = sv.PolygonZone(polygon=polygon)\n",
    "\n",
    "# create Supervision BoxAnnotator() & label_annotator()---> similar to utils.py > postprocessing_onnx()\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "# create Supervision PolygonZoneAnnotator() ---> similar to utils.py > draw_object_count()\n",
    "zone_annotator = sv.PolygonZoneAnnotator(zone=zone, color=sv.Color.WHITE, thickness=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\\yolov8s.onnx for ONNX Runtime inference...\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 51.0ms\n",
      "Speed: 2.0ms preprocess, 51.0ms inference, 4.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 51.1ms\n",
      "Speed: 4.3ms preprocess, 51.1ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 53.7ms\n",
      "Speed: 2.0ms preprocess, 53.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 61.6ms\n",
      "Speed: 1.0ms preprocess, 61.6ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 118.0ms\n",
      "Speed: 3.2ms preprocess, 118.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 50.5ms\n",
      "Speed: 2.0ms preprocess, 50.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 64.2ms\n",
      "Speed: 12.6ms preprocess, 64.2ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 56.6ms\n",
      "Speed: 6.6ms preprocess, 56.6ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 70.9ms\n",
      "Speed: 7.9ms preprocess, 70.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 57.8ms\n",
      "Speed: 5.0ms preprocess, 57.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 52.4ms\n",
      "Speed: 4.0ms preprocess, 52.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 47.0ms\n",
      "Speed: 3.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 53.7ms\n",
      "Speed: 2.0ms preprocess, 53.7ms inference, 4.7ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 50.5ms\n",
      "Speed: 1.0ms preprocess, 50.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 52.0ms\n",
      "Speed: 1.0ms preprocess, 52.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 55.8ms\n",
      "Speed: 1.0ms preprocess, 55.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 81.4ms\n",
      "Speed: 16.5ms preprocess, 81.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 1 chair, 42.6ms\n",
      "Speed: 1.0ms preprocess, 42.6ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 1 chair, 43.0ms\n",
      "Speed: 3.0ms preprocess, 43.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.7ms\n",
      "Speed: 2.0ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 44.0ms\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.9ms\n",
      "Speed: 2.0ms preprocess, 42.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.8ms\n",
      "Speed: 0.0ms preprocess, 42.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 40.4ms\n",
      "Speed: 1.0ms preprocess, 40.4ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 40.7ms\n",
      "Speed: 2.0ms preprocess, 40.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.6ms\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.9ms\n",
      "Speed: 1.0ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 43.6ms\n",
      "Speed: 1.6ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 42.0ms\n",
      "Speed: 2.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 44.5ms\n",
      "Speed: 1.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 44.1ms\n",
      "Speed: 1.0ms preprocess, 44.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 45.8ms\n",
      "Speed: 0.0ms preprocess, 45.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 42.4ms\n",
      "Speed: 1.0ms preprocess, 42.4ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.5ms\n",
      "Speed: 2.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.5ms\n",
      "Speed: 2.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 41.7ms\n",
      "Speed: 1.0ms preprocess, 41.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.6ms\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.1ms\n",
      "Speed: 2.0ms preprocess, 43.1ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.1ms\n",
      "Speed: 1.5ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.1ms\n",
      "Speed: 1.0ms preprocess, 42.1ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 44.8ms\n",
      "Speed: 1.0ms preprocess, 44.8ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 41.5ms\n",
      "Speed: 2.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 41.5ms\n",
      "Speed: 2.0ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 41.4ms\n",
      "Speed: 1.0ms preprocess, 41.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 44.5ms\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 44.2ms\n",
      "Speed: 0.6ms preprocess, 44.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.4ms\n",
      "Speed: 1.0ms preprocess, 42.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.2ms\n",
      "Speed: 1.0ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.0ms\n",
      "Speed: 2.0ms preprocess, 42.0ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.0ms\n",
      "Speed: 2.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n"
     ]
    }
   ],
   "source": [
    "# load Yolo V8 ONNX using Ultralytics Yolo\n",
    "model = \"model/yolov8s.onnx\"\n",
    "model = YOLO(model, task='detect')\n",
    "\n",
    "# load video mall.mp4\n",
    "cap = cv2.VideoCapture(\"mall.mp4\")\n",
    "           \n",
    "# iterate for each frame in video\n",
    "while cap.isOpened():\n",
    "    # get image on each frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # do forward pass (inferencing) yolo v8 onnx\n",
    "    results = model(frame, imgsz=320)[0]\n",
    "\n",
    "    # do postprocess detection result\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    detections = detections[detections.class_id == 0] # filter only class_id = 0 --> 'person'\n",
    "    zone.trigger(detections=detections)\n",
    "\n",
    "    # draw bounding box, label \n",
    "    box_labels = [\n",
    "        f\"{class_name} {confidence:.2f}\"\n",
    "        for class_name, confidence\n",
    "        in zip(detections['class_name'], detections.confidence)\n",
    "    ]\n",
    "    frame = box_annotator.annotate(scene=frame, detections=detections)\n",
    "    frame = label_annotator.annotate(scene=frame, detections=detections, labels=box_labels)\n",
    "\n",
    "    # draw polygon zone and object count label\n",
    "    object_count_label = f\"count {zone_annotator.zone.current_count}\"\n",
    "    frame = zone_annotator.annotate(scene=frame, label=object_count_label)\n",
    "\n",
    "    # show result\n",
    "    cv2.imshow('Frame',frame)\n",
    "\n",
    "    # wait 1ms per frame and close using 'q'\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Multiple Polygon Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste the polygon point here!\n",
    "polygon1 = np.array([[421, 390], [524, 470], [190, 472], [241, 398]]) # CHANGE TO YOUR OWN POLYGON\n",
    "polygon2 = np.array([[35, 684], [118, 578], [649, 569], [822, 693]])  # CHANGE TO YOUR OWN POLYGON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create supervision PolygonZone for the given polygon point\n",
    "zone1 = sv.PolygonZone(polygon=polygon1)\n",
    "zone2 = sv.PolygonZone(polygon=polygon2)\n",
    "\n",
    "# create Supervision BoxAnnotator() & label_annotator()---> similar to utils.py > postprocessing_onnx()\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "# create Supervision PolygonZoneAnnotator() ---> similar to utils.py > draw_object_count()\n",
    "zone_annotator1 = sv.PolygonZoneAnnotator(zone=zone1, color=sv.Color.WHITE, thickness=2)\n",
    "zone_annotator2 = sv.PolygonZoneAnnotator(zone=zone2, color=sv.Color.WHITE, thickness=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\\yolov8s.onnx for ONNX Runtime inference...\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 66.8ms\n",
      "Speed: 4.0ms preprocess, 66.8ms inference, 1.1ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 57.7ms\n",
      "Speed: 1.4ms preprocess, 57.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 43.2ms\n",
      "Speed: 2.3ms preprocess, 43.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 42.2ms\n",
      "Speed: 2.0ms preprocess, 42.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 45.6ms\n",
      "Speed: 1.1ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 42.2ms\n",
      "Speed: 1.5ms preprocess, 42.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 37.3ms\n",
      "Speed: 1.0ms preprocess, 37.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 43.5ms\n",
      "Speed: 1.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 46.1ms\n",
      "Speed: 2.0ms preprocess, 46.1ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 46.5ms\n",
      "Speed: 1.0ms preprocess, 46.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 45.2ms\n",
      "Speed: 1.0ms preprocess, 45.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 39.9ms\n",
      "Speed: 1.0ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 42.8ms\n",
      "Speed: 1.9ms preprocess, 42.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 43.3ms\n",
      "Speed: 0.6ms preprocess, 43.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 42.8ms\n",
      "Speed: 2.0ms preprocess, 42.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 1 chair, 40.5ms\n",
      "Speed: 2.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 1 chair, 40.0ms\n",
      "Speed: 1.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 1 chair, 34.2ms\n",
      "Speed: 1.0ms preprocess, 34.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.0ms\n",
      "Speed: 1.4ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 41.6ms\n",
      "Speed: 2.0ms preprocess, 41.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.3ms\n",
      "Speed: 2.6ms preprocess, 42.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 40.5ms\n",
      "Speed: 1.0ms preprocess, 40.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.9ms\n",
      "Speed: 1.0ms preprocess, 43.9ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 45.0ms\n",
      "Speed: 0.0ms preprocess, 45.0ms inference, 0.8ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.4ms\n",
      "Speed: 2.0ms preprocess, 42.4ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.0ms\n",
      "Speed: 1.0ms preprocess, 42.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.5ms\n",
      "Speed: 3.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 43.0ms\n",
      "Speed: 2.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 42.3ms\n",
      "Speed: 1.0ms preprocess, 42.3ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 40.0ms\n",
      "Speed: 1.1ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 41.1ms\n",
      "Speed: 1.0ms preprocess, 41.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.2ms\n",
      "Speed: 0.5ms preprocess, 42.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 43.5ms\n",
      "Speed: 2.0ms preprocess, 43.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 2 persons, 43.0ms\n",
      "Speed: 1.1ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 35.6ms\n",
      "Speed: 1.0ms preprocess, 35.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 45.5ms\n",
      "Speed: 0.0ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 30.6ms\n",
      "Speed: 0.0ms preprocess, 30.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.0ms\n",
      "Speed: 1.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 41.5ms\n",
      "Speed: 1.5ms preprocess, 41.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.5ms\n",
      "Speed: 1.0ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.0ms\n",
      "Speed: 2.0ms preprocess, 42.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.0ms\n",
      "Speed: 7.0ms preprocess, 43.0ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 40.5ms\n",
      "Speed: 2.0ms preprocess, 40.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 44.0ms\n",
      "Speed: 3.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 39.0ms\n",
      "Speed: 1.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.2ms\n",
      "Speed: 1.0ms preprocess, 42.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 37.5ms\n",
      "Speed: 1.0ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 42.7ms\n",
      "Speed: 1.0ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.6ms\n",
      "Speed: 1.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 45.6ms\n",
      "Speed: 1.0ms preprocess, 45.6ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 30.7ms\n",
      "Speed: 0.0ms preprocess, 30.7ms inference, 15.6ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 44.0ms\n",
      "Speed: 3.6ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n",
      "\n",
      "0: 320x320 1 person, 43.7ms\n",
      "Speed: 1.0ms preprocess, 43.7ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 320)\n"
     ]
    }
   ],
   "source": [
    "# load Yolo V8 ONNX using Ultralytics Yolo\n",
    "model = \"model/yolov8s.onnx\"\n",
    "model = YOLO(model, task='detect')\n",
    "\n",
    "# load video mall.mp4\n",
    "cap = cv2.VideoCapture(\"mall.mp4\")\n",
    "           \n",
    "# iterate for each frame in video\n",
    "while cap.isOpened():\n",
    "    # get image on each frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # do forward pass (inferencing) yolo v8 onnx\n",
    "    results = model(frame, imgsz=320)[0]\n",
    "\n",
    "    # do postprocess detection result\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "    detections = detections[detections.class_id == 0] # filter only class_id = 0 --> 'person'\n",
    "    zone1.trigger(detections=detections)\n",
    "    zone2.trigger(detections=detections)\n",
    "\n",
    "    # draw bounding box, label \n",
    "    box_labels = [\n",
    "        f\"{class_name} {confidence:.2f}\"\n",
    "        for class_name, confidence\n",
    "        in zip(detections['class_name'], detections.confidence)\n",
    "    ]\n",
    "    frame = box_annotator.annotate(scene=frame, detections=detections)\n",
    "    frame = label_annotator.annotate(scene=frame, detections=detections, labels=box_labels)\n",
    "\n",
    "    # draw polygon zone and object count label\n",
    "    object_count_label1 = f\"count {zone_annotator1.zone.current_count}\"\n",
    "    frame = zone_annotator1.annotate(scene=frame, label=object_count_label1)\n",
    "\n",
    "    object_count_label2 = f\"count {zone_annotator1.zone.current_count}\"\n",
    "    frame = zone_annotator2.annotate(scene=frame, label=object_count_label2)\n",
    "\n",
    "    # show result\n",
    "    cv2.imshow('Frame',frame)\n",
    "\n",
    "    # wait 1ms per frame and close using 'q'\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cons\n",
    "- Couldn't count multiple class data, all object in polygon area will be counting together as total object in polygon area\n",
    "\n",
    "### Pros\n",
    "- More faster than OpenCV DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "# Source \n",
    "- https://blog.roboflow.com/how-to-count-objects-in-a-zone/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
